# 지은이 웨스 맥키니

- 데이터 분석, 금융, 통계 계산 애플리케이션에서 파이썬 사용을 독려하고 있다.

- 모든 코드는 파이썬 3.6기반으로 수정

- pandas 라이브러리 버전을 2017년 버전

# 필수 라이브러리

1. Numpy

- 넘파이(Numerical Python, NumPy)는 파이썬 산술 계산의 주춧돌 같은 라이브러리다.

- 자료구조, 알고리즘 산술 데이터를 다루는 대부분의 과학 계산 애플리케이션에서 필요한 라이브러리를 제공한다.

- NumPy가 제공하는 기능

```

빠르고 효율적인 다차원 배열 객체 ndarray

배열 원소를 다루거나 배열 간의 수학 계산을 수행하는 함수

디스크로부터 배열 기반의 데이터를 읽거나 쓸 수 있는 도구

선형대수 계산, 푸리에 변환, 난수 생성기

파이썬 확장과 C, C++ 코드에서 NumpPy의 자료구조에 접근하고 계산 기능을 사용할 수 있도록 해주는 C API 

```

- 고속 배열 처리 외에도 NumPy는 데이터분석 알고리즘에 사용할 데이터 컨테이너의 역할을 한다.

- 수치 데이터라면 Numpy 배열은 파이썬 내장 자료구조보다 훨씬 효율적인 방법으로 데이터를 저장하고 다룰 수 있다.

2. pandas

- 팬더스(pandas)는 구조화된 데이터나 표 형식의 데이터를 빠르고 쉽고 표현적으로 다루도록 설계된 고수준의 자료구조와 함수를 제공한다.

- 2010년 처음 개발되어 파이썬으로 생산적이고 강력한 데이터 분석 환경을 구성하는 데 도움을 주고 있다.

- pandas의 주된 자료구조는 표형태의 로우와 컬럼 이름을 가지는 DataFrame(데이터프레임)과 1차원 배열 객체인 Series(시리즈)다.

- pands는 'NumPy의 고성능, 배열 연산 아이디어'에 스프레드시트와 관계형 데이터베이스(SQL 같은)의 유연한 데이터 처리 기능을 결합한 것이다.

- 세련된 색인 기능을 제공하여 데이터 변형, 자르기, 취합 그리고 데이터의 부분집합을 선택할 수 있도록 해준다.

- 데이터를 처리하고 준비하고 다듬는 과정은 데이터 분석에서 가장 중요한 부분이므로 pandas는 이 책에서 우선적으로 집중하는 라이브러리다.

- pandas의 많은 기능은 R 핵심 구현의 일부 또는 애드온 패키지에서 따왔다.

- pands라는 이름은 다차원으로 구조화된 데이터를 뜻하는 경제학 용어인 패널 데이터와 파이썬 데이터 분석에서 따온 이름이다.

3. matplotlib

- matplotlib(맷플롯립)은 그래프나 2차원 데이터 시각화를 생성하는 유명한 파이썬 라이브러리다.

- 존 D. 헌터가 만들었고 지금은 많은 개발 팀이 유지하고 있다.

- 출판물에 필요한 그래프를 만드는 데 맞춰 설계되었다.

- 기본 시각화 도구로 가장 안전한 선택이라고 생각한다.

4. IPython과 Jupyter

- IPython(아이파이썬, 인터랙티브 파이썬(Interactive Python))은 더 나은 대화형(인터랙티브) 파이썬 인터프리터를 만들 목적으로 2001년 페르난도 페레즈가 취미 프로젝트로 시작했다.

- IPython 자체는 계산이나 데이터 분석 도구로서의 기능을 제공하지는 않지만 대화형 컴퓨팅과 소프트웨어 개발 양쪽 모두에서 생산성을 극대화할 수 있도록 설계되었다.

- IPython은 많은 프로그래밍 언어들의 특징인 전통적인 편집-컴파일-실행 방식 대신에 실행-탐색 방식을 장려하며 파일시스템과 운영체제 셸에도 쉽게 접근할 수 있다.

- 2014년 페르난도와 IPython 팀은 언어에 상관없이 대화형 컴퓨팅 도구를 설계할 수 있는 주피터(Jupyter) 프로젝트를 발표했다.

- IPython 시스템은 이제 주피터에서 파이썬을 사용할 수 있게 해주는 커널(프로그래밍 언어 모드)로 역할을 변경했다.

- 주피터 노트북에서도 IPython 시스템을 여전히 사용할 수 있는데, '노트북'이라고 하는 웹 기반의 대화형 코드 작성 환경은 다양한 프로그래밍 언어를 지원한다.

- 주피터 노트북 시스템은 노트북 내용을 마크다운이나 HTML로 저장할 수 있게 한다.

- 이를 통해 코드와 텍스트를 포함하는 문서를 생성할 수 있다.

- 다른 프로그래밍 언어도 주피터 환경을 위한 커널이 구현되어 있다면 파이썬 대신 주피터 환경에서 사용할 수 있다.

- 개인적으로 파이썬 코드를 실행하거나 디버깅, 테스트 작업을 할 때는 거의 항상 IPython을 사용한다.

5. SciPy

- SciPy(사이파이)는 과학 계산 컴퓨팅 영역의 여러 기본 문제를 다루는 패키지 모음이다.

- 다음은 SciPy에 포함된 패키지 중 일부다.

```

scipy.integrate - 수치적분 루틴과 미분방적식 풀이법

scipy.linalg - numpy.linalg에서 제공하는 것보다 더 확장된 선형대수 루틴과 매트릭스 분해

scipy.optimize - 함수 최적화기와 방정식의 근을 구하는 알고리즘

scipy.signal - 시그널 프로세싱 도구

scipy.sparse - 희소 행렬과 희소 선형 시스템 풀이법

scipy.special - 감마 함수처럼 흔히 사용되는 수학 함수를 구현한 포트란 라이브러리인 SPECFUN 래퍼

scipy.stats - 표준 연속/이산 확률 분포(밀도 함수, 샘플러, 연속 분포 함수)와 다양한 통계 테스트 그리고 좀 더 기술적인 통계도구

```

- NumPy와 SciPy를 함께 사용하면 전통적인 과학 계산 애플리케이션에서 제공하는 거의 모든 기능을 대체할 수 있다.

6. scikit-learn

- scikit-leran(사이킷런)은 처음 개발되기 시작한 2010년부터 파이썬 개발자를 위한 범용 머신러닝 도구로 자리 잡기 시작했다.

- 다음과 같은 모델의 하위모듈을 포함한다.

```

분류: SVM, 최근접 이웃, 랜덤 포레스트, 로지스틱 회귀 등

회귀: 라소, 리지 회귀 등

클러스터링: K-평균, 스펙트럴 클러스터링 등

차원 축소: PCA, 특징 선택, 행렬 인수분해 등

모델 선택: 격자탐색, 교차검증, 행렬

전처리: 특징 추출, 정규화

```

7. statsmodels

- statsmodels은 다양한 R 언어용 회귀분석 모델을 구현한 스탠퍼드 대학의 통계학 교수인 조나단 테일러의 작업을 기반으로 만들어진 통계분석 패키지다.

- 스키퍼 시볼드와 죠세프 퍼크톨드가 2010년에 새로운 statsmodels 프로젝트를 시작한 이후 수많은 사용자와 오픈소스 기여자에게 빼놓을 수 없는 프로젝트로 성장했다.

- 나다니엘 스미스는 R 언어의 포뮬러 시스템에서 착안하여 statsmodels용 포뮬러 또는 모델 명세 프레임워크를 제공하는 Patsy(팻시) 프로젝트를 개발했다.

- scikit-learn과 비교하여 statsmodels는 전통적인 통계(주로 빈도주의적 접근)와 계량경제학 알고리즘을 포함하고 있다.

- 다음과 같은 하위모듈을 포함한다.

```

회귀 모델: 선형회귀, 일반화 선형 모델, 로버스트 선형 모델, 선형 혼합효과 모델 등

분산분석(ANOVA: analysis of variance)

시계열분석: AR, ARMA, ARIMA, VAR 및 기타 모델

비모수 기법: 커널밀도추정, 커널회귀

통계 모델 결과의 시각화

```

- statsmodels는 통계추론에 좀 더 초점을 맞추고 있다.

- 인자를 위한 불확실성 예측치와 p 값을 제공한다.

- 반면 scikit-learn은 좀 더 예측에 초점을 맞추고 있다.

# IPython

1. 탭 자동완성 

- an<탭키>

2. 자기관찰 ?

- add_numbers?, print?

- ??를 사용하면 가능한 경우 함수의 소스 코드도 보여준다. add_number??

- 와일드카드 기호와 함께 사용한 문자와 일치하는 모든 이름을 보여준다. np.*load*?

3. %run 명령어

- %run 명령어를 사용하면 IPython 세션 안에서 파이썬 프로그램 파일을 불러와서 실행할 수 있다.

4. 매직 명령어

- $quickref, $magic 등 사용 가능한 모든 특수 명령어를 살펴보는 것도 좋다.

# 시맨틱

- 파이썬은 가독성과 명료성 그리고 명백함을 강조한다.

- 한 줄에 여러 문장을 쓰는 것은 가독성을 해친다는 이유로 파이썬에서는 지양하는 습관이다.

- 파이썬 언어의 중요한 특징 중 하나는 객체 모델의 일관성이다.

- 파이썬에서 모든 객체는 특정한 자료형(또는 클래스)을 가지며 어떤 명백한 상황에서만 묵시적인 변환을 수행하는 자료형을 구분하는 강한 타입의 언어라고 한다.

- isinstance 함수를 이용해 어떤 객체가 무슨 자료형인지 검사할 수 있다.

- is와 is not은 변수가 None인지 검사하기 위해 흔히 사용한다.

- 뮤터블, 이뮤터블 객체

```

파이썬에서 리스트, 사전, NumPy 배열 또는 사용자 정의 클래스 같은 대부분의 객체는 변경 가능하다(뮤터블)

문자열이나 튜플은 변경 불가능하다(이뮤터블)

```

# 스칼라형

- 파이썬은 숫자 데잍어ㅘ 문자열, 불리언값(True or False) 그리고 날짜와 시간을 다룰 수있는 몇몇 내장 자료형을 제공한다.

- 이런 '단일 값'을 담는 자료형을 스칼라 타입이라고 한다.

```

None - 파이썬의 'Null' 값 (하나의 유일한 None 인스턴스만 존재한다.)

str - 문자열 자료형. 유니코드(UTF-8 인코딩) 문자열

bytes - Raw ASCII 바이트(또는 바이트로 인코딩된 유니코드)

float - 배정밀도(64비트) 부동소수점수. double 형은 따로 존재하지 않는다

bool - True or False

int - 부호가 있는(음수 표현이 가능한) 정수. 값의 범위는 플랫폼에 의존적

```

# 자료구조와 순차 자료형

# 튜플

1. 튜플은 1차원의 고정된 크기를 가지는 변경 불가능한 순차 자료형이다.

2. 튜플을 생성하는 가장 쉬운 방법은 쉼표로 구분된 값을 대입하는 것이다.

- tup = 1, 2, 3 => (1, 2, 3)

3. 괄호를 사용해서 값을 묶어줌으로써 중첩된 튜플을 정의할 수 있다. tup = (4, 5, 6), (7, 8) => ((4, 5, 6), (7, 8))

4. + 연산자를 이용해서 튜플을 이어붙일 수 있다. (4, None, 'foo') + (6, 0) + ('bar', ) => (4, None, 'foo', 6, 0, 'bar')

# 튜플에서 값 분리하기

1. 튜플과 같은 표현의 변수에 튜플을 대입하면 파이썬은 등호(=) 오른쪽에 있는 변수에서 값을 분리한다.

```

tup = 4, 5, 6

a, b, c = tup

a = 4, b = 5, c = 6

파이썬에서는 다음과 같이 하여 두 변수의 값을 쉽게 바꿀 수 있다.

b, a = a, b

튜플이나 리스트를 순회할 때도 흔히 이 기능을 활용한다

seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]

for a, b, c in seq:
    print('a={0}, b={1}, c={2}'.format(a, b, c))


a=1, b=2, c=3
a=4, b=5, c=6
a=7, b=8, c=9



```

# 리스트

1. 정렬

```

sort 함수를 이용해서 새로운 리스트를 생성하지 않고 있는 그대로 리스트를 정렬할 수 있다.

sort는 편의를 위해 몇 가지 옵션을 제공한다.

b = ['saw', 'small', 'he', 'foxes', 'six']

b.sort(key=len)

['he', 'saw', 'six', 'small', 'foxes']

```

2. 슬라이싱

```

HELLO!

string[2:4]

LL

string[-5:-2]

ELL

두 번째 콜론 다음에 간격(step)을 지정할 수 있는데, 하나 걸러 다음 원소를 선택하려면 다음과 같이 표현된다.

seq = [7, 2, 3, 6, 3, 5, 6, 0, 1]

seq[::2]

[7, 3, 3, 6, 1]

간격 값으로 -1을 사용하면 리스트나 튜플을 역순으로 반환한다.

seq[::-1]

[1, 0, 6, 5, 3, 6, 3, 2, 7]

```

# 내장 순차 자료형 함수

1. enumerate

- 순차 자료형에서 현재 아이템의 색인을 함께 처리하고자 할 때 흔히 사용한다.

```

i = 0

for value in collection:
    # value를 사용하는 코드
    i += 1

for i, value in enumerate(collection):
    # value를 사용하는 코드 작성

색인을 통해 데이터에 접근할 때 enumerate를 사용하는 유용한 패턴은 순차 자료형에서의 값과 그 위치를 dict에 넘겨주는 것이다.

```

2. zip

```

zip 함수는 여러 개의 리스트나 튜플 또는 다른 순차 자료형을 서로 짝지어서 튜플의 리스트를 생성한다.

seq1 = ['foo', 'bar', 'baz']

seq2 = ['one', 'two', 'three']

zipped = zip(seq1, seq2)

list(zipped)

[('foo', 'one'), ('bar', 'two'), ('baz', 'three')]

zip 함수의 아주 흔한 사용 예는 여러 개의 순차 자료형을 동시에 순회하는 경우인데 enumerate와 함께 사용되기도 한다.

for i, (a, b) in enumerate(zip(seq1, seq2)):
    print('{0}: {1}, {2}'.format(i, a, b))

0: foo, one
1: bar, two
2: baz, three

```

# 사전

```

dict(사전)는 파이썬 내장 자료구조 중에서 가장 중요하다.

일반적으로 해시맵 또는 연관 배열이라고도 널리 알려져 있다.

사전은 유연한 크기를 가지는 키-값 쌍으로, 키와 값은 모두 파이썬 객체다.

사전을 생성하는 방법은 중괄호 {}를 사용하여 콜론으로 구분된 키와 값을 둘러싸는 것이다.

empty_dict = {}

d1 = {'a' : 'some value', 'b' : [1, 2, 3, 4]}

d1[7] = 'an integer'

d1 = {'a' : 'some value', 'b' : [1, 2, 3, 4], 7 : 'an integer'}

del 예약어나 pop 메서드(값을 반환함과 동시에 해당 키를 삭제한다)를 사용해서 사전의 값을 삭제할 수 있다.

keys와 values 메서드는 각각 키와 값이 담긴 이터레이터를 반환한다.

키-값 쌍은 일정한 기준으로 정렬되어 있진 않지만 keys 메서드와 values 메서드에서 반환하는 리스트는 같은 순서를 가진다.

update 메서드를 사용해서 하나의 사전을 다른 사전과 합칠 수 있다.

update 메서드는 사전 값을 그 자리에서 바꾸므로 이미 존재하는 키에 대해 update를 호출하면 이전 값을 사라진다.

mapping = {}

for key, value in zip(key_list, value_list):
    mapping[key] = value

mapping = dict(zip(range(5), reversed(range(5))))

get 메서드는 기본적으로 해당 키가 존재하지 않을 경우 None을 반환하며, pop 메서드는 예외를 발생시킨다.

보통 사전에 값을 대입할 때는 리스트 같은 다른 컬렉션에 있는 값을 이용하는데, 예를 들어 여러 단어를 시작 글자에 따라 사전에 리스트로 저장하고 싶다면 다음처럼 할 수 있다.

words = ['apple', 'bat', 'bar', 'atom', 'book']

by_letter = {}

for word in words:
    letter = word[0]
    if letter not in by_letter:
        by_letter[letter] = [word]
    else:
        by_letter[letter].attend(word)
    
by_letter
{'a' : ['apple', 'atom'], 'b' : ['bat', 'bar', 'book']}

사전의 setdefault 메서드를 바로 이 목적으로 사용한다. 위 코드에서 if-else 블록은 다음처럼 작성할 수 있다.

for word in words:
    letter = word[0]
    by_letter.setdefault(letter, []).append(word)

내장 collections 모듈은 defaultdict라는 유용한 클래스를 담고 있는데, 이 클래스를 사용하면 위 과정을 좀 더 쉽게 할 수 있다.

자료형, 혹은 사전의 각 슬롯에 담길 기본값을 생성하는 함수를 넘겨서 사전을 생성하는 것이다.

from collections import defaultdict
by_letter = defaultdict(list)
for word in words:
    by_letter[word[0]].append(word)

유효한 사전 키

사전의 값으로 어떤 파이썬 객체라도 가능하지만 키는 스칼라형(정수, 실수, 문자열)이나 튜플(튜플에 저장된 값 역시 값이 바뀌지 않는 객체여야 한다)처럼 값이 바뀌지 않는 객체만 가능하다.

기술적으로는 해시 가능해야 한다는 뜻이다.

어떤 객체가 해시 가능한지(즉, 사전의 키로 사용할 수 있는지)는 hash 함수를 사용해서 검사할 수 있다.

hash('string')
50~..

hash((1, 2, (2, 3)))
10~..

hash((1, 2, [2, 3]))
Error -> 리스트는 변경이 가능하기 때문에, 리스트를 키로 하기 위해서는 tuple로 변환해야 한다.

```

# 집합

```

set(집합)은 유일한 원소만 담는 정렬되지 않은 자료형이다.

사전과 유사하지만 값은 없고 키만 가지고 있다고 생각하면 된다.

집합은 두 가지 방법으로 생성할 수 있는데 set 함수를 이용하거나 중괄호를 이용해서 생성할 수 있다.

집합은 합집합, 교집합, 차집합, 대칭차집합 같은 산술 집합 연산을 제공한다.

어떤 집합이 다른 집합의 부분집합인지 확대집합인지 검사할 수도 있다.

a_set = {1, 2, 3, 4, 5}

{1, 2, 3}.issubset(a_set)
True

a_set.issuperset({1, 2, 3})
True

{1, 2, 3} == {3, 2, 1}
True

```

# 리스트, 집합, 사전 표기법

```

리스트 표기법은 파이썬 언어에서 가장 사랑받는 기능 중 하나다.

이를 이용하면 간결한 표현으로 새로운 리스트를 만들 수 있다.

[expr for val in collection if condition]

이를 반복문으로 구현하면 다음과 같다.

result = []

for val in collection:
    if condition:
        result.append(expr)

필터 조건은 생략 가능하다.

예를 들어 문자열 리스트가 있다면 아래처럼 문자열의 길이가 2 이하인 문자열은 제외하고 나머지를 대문자로 바꾸는 게 가능하다.

strings = ['a', 'as', 'bat', 'car', 'dove', 'python']

[x.upper() for x in strings if len(x) > 2]
['BAT', 'CAR', 'DOVE', 'PYTHON']

집합과 사전에 대해서도 리스트 표기법과 같은 방식으로 적용할 수 있다.

사전 표기법은 다음과 같다.

dict_comp = {key-expr : value-expr for value in collection if condition}

집합 표기법은 대괄호 대신 중괄호를 쓴다는 점만 빼면 리스트 표기법과 동일하다.

set_comp = {expr for value in collection if condition}

리스트 내의 문자열들의 길이를 담고 있는 집합을 생성하려면 집합 표기법을 이용하여 다음과 같이 처리할 수 있다.

unique_lengths = {len(x) for x in strings}

map 함수를 이용해서 함수적으로 표현할 수도 있다.

set(map(len, strings))

사전 표기법의 예제로, 리스트에서 문자열의 위치를 담고 있는 사전을 생성하보자

loc_mapping = {val : index for index, val in enumerate(strings)}

loc_mapping
{'a': 0, 'as': 1, 'bat' : 2, 'car' : 3, 'dove' : 4, 'python' : 5}

중첩된 리스트 표기법

다음과 같이 영어 이름과 스페인어 이름을 담고 있는 리스트의 리스트가 있다고 하자.

all_data = [['John', 'Emily', 'Michael', 'Mary', 'Steven'], ['Maria', 'Juan', 'Javier', 'Natalia', 'Pilar']]

몇몇 파일에서 이들 이름을 읽어 와서 영어와 스페인어 이름을 따로 저장했으며 각 이름에서 알파벳 e가 2개 이상 포함된 이름의 목록을 구한다고 가정하자.

리스트는 for 문을 사용해서 다음처럼 구할 수 있다.

names_of_interest = []

for names in all_data:
    enough_es = [name for name in names if name.count('e') >= 2]
    names_of_interest.extends(enough_es)

위 코드 전체를 중첩된 리스트 표기법을 이용해서 다음처럼 한 번에 구현할 수 있다.

result = [name for names in all_data for name in names if name.count('e') >= 2]

```

# 네임스페이스, 스코프, 지역 함수

```

함수는 전역과 지역, 두 가지 스코프(영역)에서 변수를 참조한다.

변수의 스코프를 설명하는 다른 용어로 네임스페이스가 있다.

함수 내에서 선언된 변수는 기본적으로 모두 지역 네임스페이스에 속한다.

지역 네임스페이스는 함수가 호출될 때 생성되며 함수의 인자를 통해 즉시 생성된다.

함수의 실행이 끝나면 지역 네임스페이스는 사라진다

def func():
    a = []
    for i in range(5):
        a.append(i)

```

# 여러 값 반환하기

```

하나의 함수에서 여러 개의 값을 반환할 수 있다.

def f():
    a = 5
    b = 6
    c = 7
    return a, b, c

a, b, c = f()

데이터 분석과 과학 계산 애플리케이션에서는 많은 함수가 여러 개의 값을 반환하는 일이 잦다는 사실을 깨닫게 될 것이다.

앞서 살펴본 튜플을 생각해보면 이 함수는 하나의 객체, 말하자면 튜플을 반환한다고 생각할 수 있다.

return_value = f()

여기서 return_value는 짐작한 대로 반환된 세 개의 값을 가지고 있는 튜플이 된다.

다른 매력적인 대안으로는 여러 값을 반환하는 대신 사전 형태로 반환하는 것이다.

def f():
    a = 5
    b = 6
    c = 7
    return {'a' : a, 'b' : b, 'c' : c}

```

# 익명 함수

```

파이썬은 익명(anonymous)함수 혹은 람다(lambda)함수라고 하는 값을 반환하는 단순한 한 문장으로 이루어진 함수를 지원한다.

lambda 예약어로 정의하며, 이는 '익명 함수를 선언한다'라는 의미다.

def short_function(x):
    return x * 2

equiv_anon = lambda x: x * 2

람다 함수는 데이터 분석에서 특히 편리한데, 이는 앞으로 알게 되겠지만 데이터를 변형하는 함수에서 인자로 함수를 받아야 하는 경우가 매우 많기 때문이다.

즉, 람다 함수를 사용하면 실제 함수를 선언하거나 람다 함수를 지역 변수에 대입하는 것보다 코드를 적게 쓰고 더 간결해지기 때문이다.

def apply_to_list(some_list, f):
    return [f(x) for x in some_list]

ints = [4, 0, 1, 5, 6]
apply_to_list(ints, lambda x: x * 2)

물론 [x * 2 for x in ints]라고 해도 되지만 이렇게 하면 apply_to_list 함수에 사용자 연산을 간결하게 전달할 수 있다.

다른 예제로, 다음 문자열 리스트를 각 문자열에서 다양한 문자가 포함된 순서로 정렬한다고 가정하자

strings = ['foo', 'card', 'bar', 'aaaa', 'abab']

strings.sort(key=lambda x: len(set(list(x))))

strings
['aaaa', 'foo', 'abab', 'bar', 'card']

```

# 제너레이터

```

파이썬은 리스트 내의 객체나 파일의 각 로우 같은 순차적인 자료를 순회하는 일반적인 방법을 제공한다.

이터레이터 프로토콜을 이용해 순회 가능한 객체를 만들 수 있다.

예를 들어 사전을 순회하면 사전의 키가 반환된다.

some_dict = {'a' : 1, 'b': 2, 'c': 3}

dict_iterator = iter(some_dict)

list(dict_iterator)

['a', 'b', 'c']

제너레이터를 생성하는 더 간단한 방법은 제너레이터 표현식을 사용하는 것이다.

다음은 리스트, 사전, 집합 표현식과 유사한 방식으로 제너레이터를 생성한다.

리스트 표현식에서 대괄호를 사용하듯이 괄호를 사용해서 제너레이터를 생성할 수 있다.

gen = (x ** 2 for x in range(100))

dict((i, i**2) for i in range(5))
{0: 0, 1: 1, 2: 4, 3: 9, 4: 16}

```


# NumPy 기본: 배열과 벡터 ㅕㅇㄴ산

1. NumPy에서 제공하는 것들

```

효율적인 다차원 배열인 ndarray는 빠른 배열 계산과 유연한 브로드캐스팅 기능을 제공한다.

반복문을 작성할 필요 없이 전체 데이터 배열을 빠르게 계산할 수 있는 표준 수학 함수

배열 데이터를 디스크에 쓰거나 읽을 수 있는 도구와 메모리에 적재된 파일을 다루는 도구

선형대수, 난수 생성기, 푸리에 변환 기능

C, C++, 포트란으로 작성한 코드를 연결할 수 있는 C API

```

2. 대부분의 데이터 분석 애플리케이션에서 필자가 중요하게 생각하는 기능

```

벡터 배열 상에서 데이터 가공(데이터 먼징 또는 데이터 랭글링), 정제, 부분집합, 필터링, 변형 그리고 다른 여러 종류의 연산을 빠르게 수행

정렬, 유일 원소 찾기, 집합 연산 같은 일반적인 배열 처리 알고리즘

통계의 효과적인 표현과 데이터를 수집 요약하기

다양한 종류의 데이터를 병합하고 엮기 위한 데이터 정렬과 데이터 간의 관계 조작

내부에서 if - elif - else를 사용하는 반복문 대신 사용할 수 있는 조건절 표현을 허용하는 배열 처리

데이터 묶음 전체에 적용할 수 있는 수집, 변형, 함수 적용 같은 데이터 처리

```

3. NumPy는 일반적인 산술 데이터 처리를 위한 기반 라이브러리를 제공하기 때문에 많은 독자가 통계나 분석, 특히 표 형식의 데이터를 처리하기 위해 pandas를 사용하기 원할 것이다.

4. NumPy가 파이썬 산술 계산 영역에서 중요한 위치를 차지하는 이유 중 하나는 대용량 데이터 배열을 효율적으로 다룰 수 있도록 설계되었다는 점이다.

```

NumPy는 내부적으로 데이터를 다른 내장 파이썬 객체와 구분된 연속된 메모리 블록에 저장한다.

NumPy의 각종 알고리즘은 모두 C로 작성되어 타입 검사나 다른 오버헤드 없이 메모리를 직접 조작할 수 있다.

NumPy 배열은 또한 내장 파이썬의 연속된 자료형들보다 훨씬 더 적은 메모리를 사용한다.

NumPy 연산은 파이썬 반복문을 사용하지 않고 전체 배열에 대한 복잡한 계산을 수행할 수 있다.

```

# ndarray 생성하기

```

배열을 생성하는 가장 쉬운 방법은 array 함수를 이용하는 것이다.

순차적인 객체(다른 배열도 포함하여)를 넘겨받고, 넘겨받은 데이터가 들어 있는 새로운 NumPy 배열을 생성한다.

예를 들어 파이썬의 리스트는 변환하기 좋은 예다.

data1 = [6, 7.5, 8, 0, 1]

arr1 = np.array(data1)

arr1

array([6 ,7.5 , 8. , 0. , 1.])

배열 생성 함수 표 4.1 (139P)

```

# ndarray의 dtype

1. dtype은 ndarray가 메모리에 있는 특정 데이터를 해석하기 위해 필요한 정보(또는 메타데이터)를 담고 있는 특수한 객체다.

```

arr1 = np.array([1, 2, 3], dtype=np.float64)

arr1.dtype
dtype('float64')

ndarray의 astype 메서드를 사용해서 배열의 dtype을 다른 형으로 명시적으로 변환(또는 캐스팅) 가능하다.

arr = np.array([1, 2, 3, 4, 5])

arr.dtype
dtype('int64')

float_arr = arr.astype(np.float64)

float_arr.dtype
dtye('float64')

```

# NumPy 배열의 산술 연산

1. 배열의 중요한 특징은 for 문을 작성하지 않고 데이터를 일괄 처리할 수 있다는 것이다.

2. 이를 벡터화라고 하는데, 같은 크기의 배열 간의 산술 연산은 배열의 각 원소 단위로 적용된다.

# 색인과 슬라이싱 기초

1. NumPy 배열 색인에 대해서는 다룰 주제가 많다.

2. 데이터의 부분집합이나 개별 요소를 선택하기 위한 수많은 방법이 존재한다.

3. 1차원 배열은 단순한데, 표면적으로는 파이썬의 리스트와 유사하게 동작한다.

```

arr = np.arange(10)

arr
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

arr[5]
5

arr[5:8]
array([5, 6, 7])

arr[5:8] = 12

arr
array([0, 1, 2, 3, 4, 12, 12, 12, 8, 9])

배열 조각에 스칼라 값을 대입하면 12가 선택 영연 전체로 전파(또는 브로드캐스팅)된다.

리스트와의 중요한 차이점은 배열 조각은 원본 배열의 뷰라는 점이다.

즉, 데이터는 복사되지 않고 뷰에 대한 변경은 그대로 원본 배열에 반영된다.

arr_slice = arr[5:8]

arr_slice
array([12, 12, 12])

arr_slice[1] = 12345

arr
array([0, 1, 2, 3, 4, 12, 12345, 12, 8, 9])

arr_slice[:] = 64

arr
array([0, 1, 2, 3, 4, 64, 64, 64, 8, 9])

NumPy를 처음 접한다면, 특히 데이터 복사가 자주 일어나는 다른 배열 프로그래밍 언어를 사용해본 적이 있다면 데이터가 복사되지 않는다는 점은 놀랄 만한 사실이다.

NumPy는 대용량의 데이터 처리를 염두에 두고 설계되었기 때문에 만약 NumPy가 데이터 복사를 남발한다면 성능과 메모리 문제에 마주치게 될 것이다.

다차원 배열을 다룰 때는 좀 더 많은 옵션이 있다.

2차원 배열에서 각 색인에 해당하는 요소는 스칼라값이 아니라 1차원 배열이다.

arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

arr2d[2]
array([7, 8, 9]

개별 요소는 재귀적으로 접근하거나 콤마로 구분된 색인 리스트를 넘기면된다.

arr2d[0][2]
3

arr2d[0, 2]
3




```

# 배열 전치와 축 바꾸기

1. 배열 전치는 데이터를 복사하지 않고 데이터의 모양이 바뀐 뷰를 반환하는 특별한 기능이다.

2. ndarray는 transpose 메서드와 T라는 이름의 특수한 속성을 가지고 있다.

```

arr = np.arange(15).reshape((3, 5))

arr.T = 5, 3 쉐입으로 보여줌

```

# 유니버설 함수: 배열의 각 원소를 빠르게 처리하는 함수

1. ufunc라고 불리기도 하는 유니버설 함수는 ndarray 안에 있는 데이터 원소별로 연산을 수행하는 함수다.

2. 유니버설 함수는 하나 이상의 스칼라값을 받아서 하나 이상의 스칼라 결괏값을 반환하는 간단한 함수를 고속으로 수행할 수 있는 벡터화된 래퍼 함수라고 생각하면 된다.

3. 많은 ufunc는 sqrt나 exp같은 간단한 변형을 전체 원소에 적용할 수 있다.

```

arr = np.arange(10)

arr
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

단항 유니버설 함수

np.sqrt(arr)
array([0, 1, 1.4142, 1.7321, 2. , 2.2361, 2.4495, 2.6458, 2.8284, 3. ])


표 4-3 단항 유니버설 함수, 표 4-4 이항 유니버설 함수 (160P)


```

# 배열을 이용한 배열지향 프로그래밍 

1. NumPy 배열을 사용하면 반복문을 작성하지 않고 간결한 배열 연상을 사용해 많은 종류의 데이터 처리 작업을 할 수 있다.

2. 배열 연산을 사용해서 반복문을 명시적으로 제거하는 기법을 흔히 벡터화라고 부르는데, 일반적으로 벡터화된 배열에 대한 산술 연산은 순수 파이썬 연산에 비해 2~3배에서 많게는 수십, 수백 배까지 빠르다.

3. 간단한 예로 값이 놓여 있는 그리드에서 sqrt(x^2 + y^2)을 계산한다고 하자.

4. np.meshgrid 함수는 두 개의 1차원 배열을 받아서 가능한 모든 (x, y) 짝을 만들 수 있는 2차원 배열 두 개를 반환한다.

```

points = np.arange(-5, 0, 0.01) # -5부터 4.99까지 0.01씩 증가하는 값들의 배열

xs, ys = np.meshgrid(points, points)

ys = ...

z = np.sqrt(xs ** 2 + ys ** 2)

여기서 matplotlib을 이용해서 이 2차원 배열을 시각화할 수 있다.

import matploilib.pyplot as pit

pit.imshow(z, cmap=pit.cm.gray); pit.colorbar()

pit.title("Image plot of $\sqrt{x^2 + y^2}$ for a grid of values")

```

# 배열 연산으로 조건절 표현하기

```

numpy.where 함수는 x if 조건 else y 같은 삼항식의 벡터화된 버전이다.

다음과 같은 불리언 배열 하나와 같이 들어있는 두 개의 배열이 있다고 하자

xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])

yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])

cond = np.array([True, False, True, True, False])

cond의 값이 True일 때는 xarr의 값을 취하고 아니면 yarr의 값을 취하고 싶을 때 리스트 표기법을 이용해서 다음처럼 작성할 수 있다.

result = [(x if c else y) for x, y, c in zip(xarr, yarr, cond)]

이 부분을 

result = np.where(cond, xarr, yarr)

result
array([1.1, 2.2, 1.3, 1.4, 2.5])

```

# 수학 메서드와 통계 메서드

```

배열 전체 혹은 배열에서 한 축을 따르는 자료에 대한 통계를 계산하는 수학 함수는 배열 메서드로 사용할 수 있다.

전체의 합(sum)이나 평균(mean), 표준편차(std)는 NumPy의 최상위 함수를 이용하거나 배열의 인스턴스 메서드를 사용해서 구할 수 있다.

임의의 정규 분포 데이터를 생성하고 집계해보자.

arr = np.random.randn(5, 4)

arr.mean()

np.mean(arr)

arr.sum()

```

# 불리언 배열을 위한 메서드

```

이전 메서드의 불리언 값을 True 또는 False 으로 강제할 수 있다.

따라서 sum 메서드를 실행하면 불리언 배열에서 True인 원소의 개수를 셀 수 있다.

arr = np.random.randn(100)

(arr > 0).sum() # 양수인 원소의 개수

any와 all 메서드는 불리언 배열에 특히 유용하다.

any 메서드는 하나 이상의 값이 True인지 검사하고, all 메서드는 모든 원소가 True인지 검사한다.

bools = np.array([False, False, True, False])

bools.any()
True

bools.all()
False

```

# 정렬

```

파이썬의 내장 리스트형처럼 NumPy 배열 역시 sort 메서드를 이용해서 정렬할 수 있다.

arr = np.random.randn(6)

arr.sort()

```

# 집합 관련 함수

```

NumPy는 1차원 ndarray를 위한 몇 가지 기본적인 집합 연산을 제공한다.

아마도 가장 자주 사용하는 함수는 배열 내에서 중복된 원소를 제거하고 남은 원소를 정렬된 형태로 반환하는 np.unique일 것이다.

names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])

np.unique(names)
array(['Bob', 'Joe', 'Will'])

np.unique를 순수 파이썬만으로 구현하면?

sorted(set(names))

```

# 배열 데이터의 파일 입출력

```

NumPy는 디스크에서 텍스트나 바이너리 형식의 데이터를 불러오거나 저장할 수 있다.

여기서는 NumPy의 내장 이진 형식만 살펴본다.

많은 사람이 텍스트나 표 형식의 데이터는 pandas나 다른 도구를 사용해서 처리하는 것을 선호하므로 6장에서 더 살펴보도록 하자.

np.save와 np.load는 배열 데이터를 효과적으로 디스크에 저장하고 불러오기 위한 함수다.

배열은 기본적으로 압축되지 않은 원시(가공되지 않은) 바이너리 형식의 .npy파일로 저장된다.

arr = np.arange(10)

np.save('some_array', arr)

저장되는 파일 경로가 .npy로 끝나지 않으면 자동적으로 확장자가 추가된다.

np.load('some_array.npy)

```

# 선형대수

```

행렬의 곱셈, 분할, 행렬식, 그리고 정사각 행렬 수학 같은 선형대수는 배열을 다루는 라이브러리에서 중요한 부분이다.

매트랩 같은 언어와 다르게 두 개의 2차원 배열을 * 연산자로 곱하면 행렬 곱셈이 아니라 대응하는 각각의 원소의 곱을 계산한다.

행렬 곱센은 배열 메서드이자 numpy 네임스페이스 안에 있는 dot 함수를 이용해서 계산한다.

x = np.array([[1., 2., 3.], [4., 5., 6.]])

y = np.array([[6., 23.], [-1, 7], [8, 9]])

x.dot(y)

```

# pandas 시작하기

```

pandas는 앞으로 가장 자주 살펴볼 라이브러리다. 고수준의 자료구조와 파이썬에서 빠르고 쉽게 사용할 수 있는 데이터 분석 도구를 포함하고 있다.

pandas는 다른 산술 계산 도구인 NumPy와 SciPy, 분석 라이브러리인 statsmodels와 scikit-learn, 시각화 도구인 matplotlib과 함께 사용하는 경우가 흔하다.

pandas는 for 문을 사용하지 않고 데이터를 처리한다거나 배열 기반의 함수를 제공하는 등 NumPy의 배열 기반 계산 스타일을 많이 차용했다.

pandas가 NumPy의 스타일을 많이 차용했지만 갖아 큰 차이점은 pandas는 표 형식의 데이터나 다양한 형태의 데이터를 다루는 데 초점을 맞춰 설계했다는 것이다.

NumPy는 단일 산술 배열 데이터를 다루는 데 특화되어 있다.

import pandas as pd

from pandas import Series, DataFrame

```

# pandas 자료구조 소개

```

pandas에 대해 알아보려면 Series와 DataFrame, 이 두 가지 자료구조에 익숙해질 필요가 있다. 이 두 가지 자료구조로 모든 문제를 해결할 순 없지만 대부분의 애플리케이션에서 사용하기 쉬우며 탄탄한 기반을 제공한다.

```

# Series

```

Series는 일련의 객체를 담을 수 있는 1차원 배열 같은 자료구조다 (어떤 NumPy 자료형이라도 담을 수 있다.) 

그리고 색인이라고 하는 배열의 데이터와 연관된 이름을 가지고 있다.

가장 간단한 Series 객체는 배열 데이터로부터 생성할 수 있다.

obj = pd.Series([4, 7, -5, 3])

obj

0 4
1 7
2 -5
3 3

Series를 이해하는 다른 방법은 고정 길이의 정렬된 사전형이라고 생각하는 것이다.

Series는 색인값에 데이터값을 매핑하고 있으므로 파이썬의 사전형과 비슷하다.

Series 객체는 파이썬의 사전형을 인자로 받아야 하는 많은 함수에서 사전형을 대체하여 사용할 수 있다.

Series의 유용한 기능은 산술 연산에서 색인과 라벨로 자동 정렬하는 것이다. 데이터베이스를 사용해본 경험이 있다면 join 연산과 비슷하다고 여겨질 것이다.

Series 객체와 Series의 색인은 모두 name 속성이 있는데 이 속성은 pandas의 핵심 기능과 밀접한 관련이 있다.

obj4.name = 'population'

obj4.index.name = 'state'

```

# DataFrame

```

DataFrame은 표 같은 스프레드시트 형식의 자료구조이고 여러 개의 컬럼이 있는데 각 컬럼은 서로 다른 종류의 값(숫자, 문자열, 불리언 등)을 담을 수 있다.

DataFrame은 로우와 컬럼에 대한 색인을 가지고 있는데, 색인의 모양이 같은 Series 객체를 담고 있는 파이썬 사전으로 생각하면 편하다.

내부적으로 데이터는 리스트나 사전 또는 1차원 배열을 담고 있는 다른 컬렉션이 아니라 하나 이상의 2차원 배열에 저장된다.

DataFrame 객체는 다양한 방법으로 생성할 수 있지만 가장 흔하게 사용되는 방법은 같은 길이의 리스트에 담긴 사전을 이용하거나 NumPy 배열을 이용하는 것이다.

data = {'state' : ['Ohio', 'Nevada'], 'year' : ['2021', '2021'], 'pop' : [1.5, 1.7]}
frame = pd.DataFrame(data)

frame
 
  pop state year
0 1.5  Ohio 2021
1 1.7 Nevada 2021

원하는 순서대로 columns를 지정하면 원하는 순서를 가진 DataFrame 객체가 생성된다.

pd.dataFrame(data, columns=['year', 'state', 'pop'])

중첩된 사전을 이용해서 데이터를 생성할 수 있다. 다음과 같은 중첩된 사전이 있다고 하자

pop = {'Nevada' : {2001: 2.4, 2002: 2.9}, 'Ohio' : {2000: 1.5, 2002:3.6}}

이 중첩된 사전을 DataFrame에 넘기면 바깥에 있는 사전의 키는 컬럼이 되고 안에 있는 키는 로우가 된다.

frame3 = pd.DataFrame(pop)

frame3

        Nevada Ohio
2000    Nan     1.5
2001    2.4     1.7
2002    2.9     3.6

NumPy 배열과 유사한 문법으로 데이터를 전치 (컬럼과 로우를 뒤집음)할 수 있다.

frame3.T

중첩된 사전을 이용해서 DataFrame을 생성할 때 안쪽에 있는 사전값은 키값별로 조합되어 결과의 색인이 되지만 색인을 직접 지정하면 지정된 색인으로 DataFrame을 생성한다. ** <- 색인을 직접 지정해서 원하는 결과 값을 도출하는 부분이 추후 중요하게 작용할 것 같다.

pd.DataFrame(pop, index=[2001, 2002, 2003])
        Nevada  Ohio   
2001    2.4     1.7
2002    2.9     3.6
2003    NaN     NaN

데이터프레임의 색인(index)과 컬럼(columns)에 name 속성을 지정했다면 이 역시 함께 출력된다.

frame3.index.name = 'year'; frame3.columns.name = 'state'

frame3

state   Nevada  Ohio
year
2000    NaN     1.5
2001    2.4     1.7
2002    2.9     3.6

Series와 유사하게 values 속성은 DataFrame에 저장된 데이터를 2차원 배열로 반환한다.

frame3.values

```


# 재색인


```

pandas 객체의 중요한 기능 중 하나는 reindex인데, 새로운 색인에 맞도록 객체를 새로 생성한다.

아래 간단한 예제를 살펴보자.

obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])

obj

d   4.5
b   7.2
a   -5.3
c   3.6

이 Series 객체에 대해 reindex를 호출하면 데이터를 새로운 색인에 맞게 재배열하고, 존재하지 않는 색인값이 있다면 NaN을 추가한다.

obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])

obj2

a   -5.3
b   7.2
c   3.6
d   4.5
e   NaN

시계열 같은 순차적인 데이터를 재색인할 때 값을 보간하거나 채워 넣어야 할 경우가 있다.

method 옵션을 이용해서 이를 해결할 수 있으며, ffill 같은 메서드를 이용해서 누락된 값을 직전의 값으로 채워 넣을 수 있다.

obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])

obj3

0   blue
2   purple
4   yellow

obj3.reindex(range(6), method='ffill')

0   blue
1   blue
2   purple
3   purple
4   yellow
5   yellow

DataFrame에 대한 reindex는 로우(색인), 컬럼 또는 둘 다 변경 가능하다. 그냥 순서만 전달하면 로우가 재색인된다.

```

# loc와 iloc로 선택하기

```

DataFrame의 로우에 대한 라벨로 색인하는 방법으로 특수한 색인 필드인 loc와 iloc를 소개한다.

이 방법을 이용하면 NumPy와 비슷한 방식에 추가적으로 축의 라벨을 사용하여 DataFrame의 로우와 컬럼을 선택할 수 있다.

축 이름을 선택할 때는 loc를, 정수 색인으로 선택할 때는 iloc를 이용한다.

축의 라벨로 하나의 로우와 여러 칼럼을 선택하기

data.loc['Colorado', ['two', 'three']]

two 5
three 6
Name : Colorado

data.lioc[2, [3, 0, 1]]

four 11
one 8
two 9
Name: Utah

이 두 함수는 슬라이스도 지원할 뿐더러 단일 라벨이나 라벨 리스트도 지원한다.

data.loc[:'Utah', 'two']

data.iloc[:, :3][data.three > 5]

```

# 산술 연산과 데이터 정렬

```

pandas에서 가장 중요한 기능 중 하나는 다른 색인을 가지고 있는 객체 간의 산술 연산이다.

객체를 더할 때 짝이 맞지 않는 색인이 있다면 결과에 두 색인이 통합된다.

데이터베이스를 사용해본 경험이 있다면 색인 라벨에 대한 외부 조인과 유사하게 동작한다고 생각할 수 있다.

예제를 보자.

s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'b', 'c', 'd'])
s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index = ['a', 'c', 'e', 'f', 'g'])

s1 + s2

a   5.2
c   1.1
d   NaN
e   0.0
f   NaN
g   NaN

서로 겹치는 색인이 없는 경우 데이터는 NaN 값이 된다. 산술 연산 시 누락된 값은 전파된다.

```

# 데이터 로딩과 저장, 파일 형식

```

이 책에서 다루는 대부분의 도구를 사용하는 첫 관문은 데이터에 접근하는 것이다.

다양한 형식의 데이터를 읽고 쓸 수 있는 많은 라이브러리가 있지만 이 책에서는 pandas에 초점을 맞춰 설명한다.

일반적으로 입출력은 몇 가지 작은 범주로 나뉘는데, 텍스트 파일을 이용하는 방법, 데이터베이스를 이용하는 방법, 웹 API를 이용해서 네트워크를 통해 불러오는 방법이 있다.

pandas에는 표 형식의 자료를 DataFrame 객체로 읽어오는 몇 가지 기능을 제공하고 있다.

아마 read_csv와 read_table을 주로 사용하게 될 테지만 표 6-1에 다른 함수도 정리해두었다.

```

# JSON 데이터

```

JSON (Javascript Object Notation)은 웹브라우저와 다른 애플리케이션이 HTTP 요청을 ㅗ데이터를 보낼 때 널리 사용하는 표준 파일 형식 중 하나다.

JSON은 CSV 같은 표 형식의 텍스트보다 좀 더 유연한 데이터 형식이다.

기본 자료형은 객체(사전), 배열(리스트), 문자열, 숫자, 불리언, 그리고 널이다. 객체의 키는 반드시 문자열이어야 한다.

JSON 데이터를 읽고 쓸 수 있는 파이썬 라이브러리가 몇 가지 있는데 여기서는 파이썬 표준 라이브러리인 json을 사용하겠다.

JSON 문자열을 파이썬 형태로 변환하기 위해서는 json.loads를 사용한다.

import json

result = json.loads(obj)

json.dumps는 파이썬 객체를 JSON 형태로 변환한다.

asjson = json.dumps(result)

pandas의 데이터를 JSON으로 저장하는 한 가지 방법은 Series나 DataFrame의 to_json함수를 이용하는 것이다.

data = pd.read_json('examples/example.json')

print(data.to_json())

```

# XML과 HTML: 웹 스크래핑

```

파이썬에는 lxml, Beautiful Soup(뷰티플 수프), 그리고 html5lib 같은 HTML과 XML 형식의 데이터를 읽고 쓸 수 있는 라이브러리가 무척 많다.

그중에서도 lxml은 가장 빠르게 동작하고 깨진 HTML과 XML 파일도 잘 처리해준다.

pandas에는 read_html이라는 내장 함수가 있다. 이는 lxml이나 Beautiful Soup 같은 라이브러리를 사용해서 자동으로 HTML 파일을 파싱하여 DataFrame으로 변환해준다.

```

# lxml.objectify를 이용해서 XML 파싱하기

```

XML(eXtensible MarkUp Language)은 계층적 구조와 메타데이터를 포함하는 중첩된 데이터 구조를 지원하는 또 다른 유명한 데이터 형식이다.

앞에서는 HTML에서 데이터를 파싱하기 위해 내부적으로 lxml 또는 Beautiful Soup을 사용하는 pandas.read_html 함수를 살펴봤다.

```

# 이진 데이터 형식

```

데이터를 효율적으로 저장하는 가장 손쉬운 방법은 파이썬에 기본으로 내장되어 있는 pickle 직렬화를 사용해 데이터를 이진 형식으로 저장하는 것이다.

편리하게도 pandas 객체는 모두 pickle을 이용해서 데이터를 저장하는 to_pickle 메서드를 가지고 있다.

pickle로 직렬화된 객체는 내장 함수인 pickle로 직접 불러오거나 아니면 좀 더 편리한 pickle 함수인 pandas.read_pickle 메서드를 이용해서 불러올 수 있다.

pickle은 오래 보관할 필요가 없는 데이터일 경우에만 추천한다.

pandas는 HDF5와 Message-Pack, 두 가지 바이너리 포맷을 지원한다.

```

# HDF5 형식 사용하기

```

HDF5는 대량의 과학 계산용 배열 데이터를 저장하기 위해 고안된 훌륭한 파일 포맷이다.

C 라이브러리로도 존재하며 자바, 줄리아, 매트랩, 그리고 파이썬 같은 다양한 다른 언어에서도 사용할 수 있는 인터페이스를 제공한다.

HDF는 Hierarchical Data Format의 약자로 계층적 데이터 형식이라는 뜻이다.

각각의 HDF5 파일은 여러 개의 데이터셋을 저장하고 부가 정보를 기록할 수 있다.

보다 단순한 형식과 비교하면 HDF5는 다양한 압축 기술을 사용해서 온더플라이(실시간) 압축을 지원하며 반복되는 패턴을 가진 데이터를 좀 더 효과적으로 저장할 수 있다.

메모리에 모두 적재할 수 없는 엄청나게 큰 데이터를 아주 큰 배열에서 필요한 작은 부분들만 효과적으로 읽고 쓸 수 있는 훌륭한 선택이다.

PyTables나 h5py 라이브러리를 이용해서 직접 HDF5 파일에 접근하는 것도 가능하지만 pandas는 Series나 DataFrame 객체로 간단히 저장할 수 있는 고수준의 인터페이스를 제공한다.

HDFStore 클래스는 사전처럼 작동하며 세밀한 요구 사항도 잘 처리해준다.

```

# 마이크로소프트 엑셀 파일에서 데이터 읽어오기

```

pandas는 ExcelFile 클래스나 pandas.read_excel 함수를 이용해서 마이크로소프트 엑셀 2003 이후 버전의 데이터를 읽어올 수 있다.

내부적으로 이들 도구는 XLS 파일과 XLSX 파일을 읽기 위해 각각 xlrd와 openpyxl 패키지를 이용하므로 사용하기 전에 pip나 conda 명령을 이용해서 두 패키지를 설치해야 한다.

ExcelFile 클래스를 사용하려면 xls나 xlsx 파일의 경로를 지정하여 객체를 생성해야 한다.

xlsx = pd.ExcelFile('examples/ex1.xlsx')

시트에 있는 데이터는 parse 함수를 이용해서 DataFrame으로 읽어올 수 있다.

pd.read_excel(xlsx, 'Sheet1')

```

# 데이터 정제 및 준비

```

데이터 분석과 모델링 작업에서는 데이터를 불러오고, 정제하고, 변형하고, 재정렬하는 데이터 준비 과정에 많은 시간을 들이게 된다.

이런 작업들은 분석 시간의 80%를 잡아먹기도 한다.

가끔은 파일이나 데이터베이스에 저장된 데이터가 애플리케이션에서 사용하기 쉽지 않은 방식으로 저장되어 있기도 하다.

파이썬 표준 라이브러리를 pandas와 함께 사용하면 큰 수고 없이 데이터를 원하는 형태로 가공할 수 있다.

```

# 누락된 데이터 찾아내기

```

pandas 객체의 모든 기술 통계는 누락된 데이터를 배제하고 처리한다.

산술 데이터에 한해 pandas는 누락된 데이터를 실숫값인 NaN으로 처리한다.

pandas에서는 R 프로그래밍 언어에서 결측치를 NA(Not Available)로 취급하는 개념을 차용했다.

분석 애플리케이션에서 NA 데이터는 데이터가 존쟇지 않거나, 존재하더라도 데이터를 수집하는 과정 등에서 검출되지 않았음을 의미한다.

pandas 프로젝트에서는 결측치를 처리하는 방법을 개선하는 작업이 진행 중이지만 pandas.isnull 같은 사용자 API 함수에서는 성가신 부분을 추상화로 제거했다.

```

# 누락된 데이터 골라내기

```

누락된 데이터를 골라내는 몇 가지 방법이 있는데, pandas.isnull이나 불리언 색인을 사용해 직접 손으로 제거하는 것도 한 가지 방법이지만, dropna를 매우 유용하게 사용할 수 있다.

Series에 dropna 메서드를 적용하면 널이 아닌 non-null 데이터와 색인값만 들어 있는 Series를 반환한다.

```

# 결측치 채우기

```

누락된 값을 제외시키지 않고(잠재적으로 다른 데이터도 함께 버려질 가능성이 있다) 데이터 상의 '구멍'을 어떻게든 메우고 싶은 경우가 있다.

이 경우 fillna 메서드를 활용하면 되는데, fillna 메서드에 채워 넣고 싶은 값을 넘겨주면 된다.

df.fillna(0)

```

# 중복 제거하기

```

여러 가지 이유로 DataFrame에서 중복된 로우를 발견할 수 있다.

DataFrame의 duplicated 메서드는 각 로우가 중복인지 아닌지 알려주는 불리언 Series를 반환한다.

data.duplicated()

drop_duplicates는 duplicated 배열이 False인 DataFrame을 반환한다.

```

# 문자열 다루기

```

파이썬은 문자열이나 텍스트 처리의 용이함 덕분에 원시 데이터를 처리하는 인기 있는 언어가 되었다.

대부분의 텍스트 연산은 문자열 객체의 내장 메서드로 간단하게 처리할 수 있다.

좀 더 복잡한 패턴 매칭이나 텍스트 조작은 정규 표현식을 필요로 한다.

pandas는 배열 데이터 전체에 쉽게 정규 표현식을 적용하고, 누락된 데이터를 편리하게 처리할 수 있는 기능을 포함하고 있다.

```

# 문자열 객체 메서드

```

문자열을 다뤄야 하는 대부분의 애플리케이션은 내장 문자열 메서드만으로도 충분하다.

예를 들어 쉼표로 구분된 문자열은 split 메서드를 이용해서 분리할 수 있다.

val = 'a,b, guido'
val.split(',')
['a','b',' guido']

split 메서드는 종종 공백 문자 (줄바꿈 문자 포함)를 제거하는 strip 메서드와 조합해서 사용하기도 한다.

pieces = [x.strip() for x in val.split(',')]
['a', 'b', 'guido']

이렇게 분리된 문자열은 더하기 연산을 사용해서 :: 문자열과 합칠 수도 있다.

first, second, third = pieces

first + '::' + second + '::' + third
'a::b::guido'

하지만 이 방법은 실용적이면서 범용적인 메서드는 아니다.

빠르고 좀 더 파이썬스러운 방법은 리스트나 튜플을 :: 문자열의 join 메서드로 전달하는 것이다.

'::'.join(pieces)
'a::b::guido'

일치하는 부분문자열의 위치를 찾는 방법도 있다. index나 find를 사용하는 것도 가능하지만 in을 사용하면 일치하는 문자열을 쉽게 찾을 수 있다

'guido' in val
True

val.index(',')
1

val.find(':')
-1

find와 index의 차이점은 index의 경우 문자열을 찾지 못하면 예외를 발생시킨다는 것

count는 특정 부분문자열이 몇 건 발견되었는지 반환한다.

val.count(',')
2

replace는 찾아낸 패턴을 다른 문자열로 치환한다.
val.replace(',', '::')
'a::b:: guido'

count - 문자열에서 겹치지 않는 부분문자열의 개수를 반환
endswith - 문자열이 주어진 접미사로 끝날 경우 True 반환
startswith - 문자열이 주어진 접두사로 시작할 경우 True 반환
join - 문자열을 구분자로 하여 다른 문자열을 순서대로 이어붙인다.

```

# 정규 표현식

```

정규 표현식은 텍스트에서 문자열 패턴을 찾는 유연한 방법을 제공한다.

흔히 regex라 불리는 단일 표현식은 정규 표현 언어로 구성된 문자열이다.

파이썬에는 re 모듈이 내장되어 있어서 문자열에 대한 정규 표현식을 처리한다.

import re

text = "foo bar\t baz \tqux"

re.split('\s+', text)
['foo', 'bar', 'baz', 'qux']

re.split('\s+', text)를 사용하면 먼저 정규 표현식이 컴파일되고 그 다음에 split 메서드가 실행된다.

re.complie로 직접 정규 표현식을 컴파일하고 그렇게 얻은 정규 표현식 객체를 재사용하는 것도 가능하다.

regex = re.compile('\s+')
regex.split(text)
['foo', 'bar', 'baz', 'qux']

정규 표현식에 매칭되는 모든 패턴의 목록을 얻고 싶다면 findall 메서드를 사용한다.

regex.findall(text)
[' ', '\t', ' \t']

같은 정규 표현식을 다른 문자열에도 적용해야 한다면 re.compile을 이용해서 정규 표현식 객체를 만들어 쓰는 방법을 추천한다.

이렇게 하면 CPU 사용량을 아낄 수 있다.

match와 search는 findall 메서드와 관련이 있다.

findall은 문자열에서 일치하는 모든 부분 문자열을 찾아주지만 search 메서드는 패턴과 일치하는 첫 번째 존재를 반환한다.

match 메서드는 이보다 더 엄격해서 문자열의 시작부분에서 일치하는 것만 찾아준다.

sub 메서드는 찾은 패턴을 주어진 문자열로 치환하여 새로운 문자열을 반환한다.

m = regex.sub('REDACTED', text)

```

# 데이터 준비하기: 조인, 병합, 변형

```

대부분의 경우 데이터는 여러 파일이나 데이터베이스 혹은 분석하기 쉽지 않은 형태로 기록되어 있다.

이 장에서는 데이터를 합치고, 재배열할 수 있는 도구들을 살펴보자.

먼저 데이터를 병합하거나 변환하는 과정에서 사용되는 pandas의 계층적 색인의 개념을 알아보고 이를 활용하여 데이터를 다듬는 과정을 심도 있게 살펴볼 것이다.

```

# 데이터 합치기

```

pandas 객체에 저장된 데이터는 여러 가지 방법으로 합칠 수 있다.

pandas.merge는 하나 이상의 키를 기준으로 DataFrame의 로우를 합친다. SQL이나 다른 관계형 데이터베이스의 join 연산과 유사하다.

pandas.concat은 하나의 축을 따라 객체를 이어 붙인다.

combile_first 인스턴스 메서드는 두 객체를 포개서 한 객체에서 누락된 데이터를 다른 객체에 있는 값으로 채울 수 있도록 한다.

```

# 데이터베이스 스타일로 DataFrame 합치기

```

병합(merge)이나 조인 연산은 관계형 데이터베이스의 핵심적인 연산인데, 하나 이상의 키를 사용해서 데이터 집합의 로우를 합친다.

pandas의 merge 함수를 이용해서 이런 알고리즘을 데이터에 적용할 수 있다. 

merge 함수는 기본적으로 내부 조인(inner join)을 수행하여 교집합인 결과를 반환한다.

how 인자로 'left', 'right', 'outer'를 넘겨서 각각 왼쪽 조인, 오른쪽 조인, 외부 조인을 수행할 수도 있다.

외부 조인은 합집합인 결과를 반환하고 왼쪽 조인과 오른쪽 조인은 각각 왼쪽 또는 오른쪽의 모든 로우를 포함하는 결과를 반환한다.

how 옵션에 따른 다양한 조인 연산

'inner' 양쪽 테이블 모두에 존재하는 키 조합 사용

'left' 왼쪽 테이블에 존재하는 모든 키 조합 사용

'right' 오른쪽 테이블에 존재하는 모든 키 조합 사용

'outer' 양쪽 테이블에 존재하는 모든 키 조합 사용

```

# 그래프와 시각화

```

정보 시각화는 데이터 분석에서 무척 중요한 일 중 하나다.

시각화는 특잇값을 찾아내거나, 데이터 변형이 필요한지 알아보거나, 모델에 대한 아이디어를 찾기 위한 과정의 일부이기도 하다.

파이썬은 다양한 시각화 도구를 구비하고 있지만, 이 책에서는 matplotlib과 matplotlib 기반의 도구들을 우선적으로 살펴보겠다.

matplotlib은 모든 운영체제의 다양한 GUI 백엔드를 제공하고 있으며 PDF, SVG, JPG, PNG, BMP, GIF 등 일반적으로 널리 사용되는 벡터 포맷과 래스터 포맷으로 그래프를 저장할 수 있다.

이 책에 수록된 대부분의 그래프는 matplotlib을 이용해서 만들었다.

```

# pandas에서 seaborn으로 그래프 그리기

```

matplotlib는 사실 꽤 저수준의 라이브러리다.

데이터를 어떻게 보여줄 것인지부터(선그래프, 막대그래프, 산포도 등) 범례와 제목, 눈금 라벨, 주석 같은 기본 컴포넌트로 그래프를 작성해야 한다.

pandas를 사용하다 보면 로우와 컬럼 라벨을 가진 다양한 컬럼의 데이터를 다루게 된다.

pandas는 Series와 DataFrame 객체를 간단하게 시각화할 수 있는 내장 메서드를 제공한다.

다른 라이브러리로는 마이클 와스콤이 만든 통계 그래픽 라이브러리인 seaborn이 있다.

```

# 선그래프

```

Series와 DataFrame은 둘 다 plot 메서드를 이용해 다양한 형태의 그래프를 생성할 수 있다.

기본적으로 plot 메서드는 선그래프를 생성한다.

```

# 막대그래프

```

plot.bar()와 plot.barh()는 각각 수직막대그래프와 수평막대그래프를 그린다.

이 경우 Series 또는 DataFrame의 색인은 수직막대그래프(bar)인 경우 x 눈금, 수평막대그래프(barh)인 경우 y 눈금으로 사용된다.

```

# 히스토그램과 밀도 그래프

```

히스토그램은 막대그래프의 한 종류로, 값들의 빈도를 분리해서 보여준다.

데이터 포인트는 분리되어 고른 간격의 막대로 표현되며 데이터의 숫자가 막대의 높이로 표현된다.

tips['tip_pct'].plot.hist(bins=50)

```

# 산포도

```

산포도(scatter plot, point plot)는 두 개의 1차원 데이터 묶음 간의 관계를 나타내고자 할 대 유용한 그래프다.

statsmodels 프로젝트에서 macrodata 데이터 묶음을 불러온 다음 몇 가지 변수를 선택하고 로그차를 구해보자

seaborn 라이브러리의 regplot 메서드를 이용해서 산포도와 선형회귀곡선을 함께 그릴 수 있다.

```

# 패싯 그리드와 범주형 데이터

```

추가적인 그룹 차원을 가지는 데이터는 어떻게 시각화해야 할까?

다양한 범주형 값을 가지는 데이터를 시각화하는 한 가지 방법은 패싯 그리드를 이용하는 것이다.

seaborn은 factorplot이라는 유용한 내장 함수를 제공하여 다양한 면을 나타내는 그래프를 쉽게 그릴 수 있게 도와준다.

```

# 데이터 집계와 그룹 연산

```

데이터셋을 분류하고 각 그룹에 집계나 변형 같은 함수를 적용하는 건 데이터 분석 과정에서 매우 중요한 일이다.

데이터를 불러오고 취합해서 하나의 데이터 집합을 준비하고 나면 그룹 통계를 구하거나 가능하다면 피벗테이블을 구해서 보고서를 만들거나 시각화하게 된다.

pandas는 데이터 집합을 자연스럽게 나누고 요약할 수 있는 groupby라는 유연한 방법을 제공한다.


```

# Group by 메카닉

```

다수의 인기 있는 R 프로그래밍 패키지 저자인 해들리 위캠은 분리-적용-결합이라는 그룹 연산에 대한 새로운 용어를 만들었는데, 나는 이 말이 그룹 연산에 대한 훌륭한 설명이라고 생각한다.

그룹 연산의 첫 번째 단계에서는 Series, DataFrame 같은 pandas 객체나 아니면 다른 객체에 들어 있는 데이터를 하나 이상의 키를 기준으로 분리한다.

객체는 하나의 축을 기준으로 분리하는데, 예를 들어 DataFrame은 로우(axis=0)로 분리하거나 컬럼(axis=1)으로 분리할 수 있다.

분리하고 나서는 함수를 각 그룹에 적용시켜 새로운 값을 얻어낸다.

마지막으로 함수를 적용한 결과를 하나의 객체로 결합한다.


```

# 그룹 간 순회하기

```

GroupBy 객체는 이터레이션을 지원하는데, 그룹 이름과 그에 따른 데이터 묶음을 튜플로 반환한다.

for name, group in df.groupby('key1'):
    print(name)
    print(group)


```

# 시계열

```

시계열 데이터는 금융, 경제, 생태학, 신경과학, 물리학 등 여러 다양한 분야에서 사용되는 매우 중요한 구조화된 데이터다.

시간상의 여러 지점을 관측하거나 측정할 수 있는 모든 것이 시계열이다.

대부분의 시계열은 고정 빈도(fixed frequency)로 표현되는데 데이터가 존재하는 지점이 15초마다, 5분마다, 한 달에 한 번 같은 특정 규칙에 따라 고정 간격을 가지게 된다.

시계열은 또한 고정된 단위나 시간 혹은 단위들 간의 간격으로 존재하지 않고 불규칙적인 모습으로 표현 될 수 있다.

어떻게 시계열 데이터를 표시하고 참조할지는 애플리케이션에 의존적이며 다음 중 한 유형일 수 있다.

시간 내에서 특정 순간의 타임스탬프

2007년 1월이나 2010년 전체 같은 고정된 기간

시작과 끝 타임스탬프로 표시되는 시간 간격

```

# 날짜, 시간 자료형, 도구

```

파이썬 표준 라이브러리는 날짜와 시간을 위한 자료형과 달련 관련 기능을 제공하는 자료형이 존재한다.

datetime, time 그리고 calendar 모듈은 처음 공부하기에 좋은 주제다.

```

# 문자열을 datetime으로 변환하기

```

datetime 객체와 나중에 소개할 pandas의 Timestamp 객체는 str 메서드나 strftime 메서드에 포맷 규칙을 넘겨서 문자열로 나타낼 수 있다.

```

# 색인, 선택, 부분 선택

```

시계열은 라벨에 기반해서 데이터를 선택하고 인데싱할 때 pandas.Series와 동일하게 동작한다.

```

# 날짜 범위 생성하기

```

pandas.date_range를 사용하면 특정 빈도에 따라 지정한 길이만큼으 DatetimeIndex를 생성한다.

index = pd.date_range('2012-04-01', '2012-06-01')

```