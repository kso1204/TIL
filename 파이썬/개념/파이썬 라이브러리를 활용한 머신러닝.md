# 파이썬 라이브러리를 활용한 머신 러닝

# 소개

1. 머신러닝은 데이터에서 지식을 추출하는 작업이다.

2. 머신러닝은 통계학, 인공지능 그리고 컴퓨터 과학이 얽혀 있는 연구 분야이며 예측 분석이나 통계적 머신러닝으로도 불린다.

# 머신러닝으로 풀 수 있는 문제

1. 가장 많이 사용되는 머신러닝 알고리즘들은 이미 알려진 사례를 바탕으로 일반화된 모델을 만들어 의사 결정 프로세스를 자동화하는 것들이다.

2. 이 방식을 지도 학습이라고 하며 사용자는 알고리즘에 입력과 기대되는 출력을 제공하고 알고리즘은 주어진 입력에서 원하는 출력을 만드는 방법을 찾는다.

3. 지도 학습의 예는 다음과 같다

- 편지 봉투에 손으로 쓴 우편번호 숫자 판별

- 의료 영상 이미지에 기반한 종양 판단

- 의심되는 신용카드 거래 감지

4. 이런 사례들에서 주목할 점은 입력과 출력이 상당히 직관적으로 보이지만, 데이터를 모으는 과정은 세 경우가 많이 다르다는 것이다.

5. 이 책에서 다룰 또 다른 알고리즘은 비지도 학습 알고리즘이다.

6. 비지도 학습에서는 알고리즘에 입력은 주어지지만 추력은 제공되지 않는다.

7. 이 알고리즘의 성공 사례는 많지만 비지도 학습을 이해하거나 평가하는 일은 쉽지 않다.

8. 비지도 학습의 예는 다음과 같다.

- 블로그 글의 주제 구분

- 고객들을 취향이 비슷한 그룹으로 묶기

- 비정상적인 웹사이트 접근 탐지

# 문제와 데이터 이해하기

1. 머신러닝 프로세스에서 가장 중요한 과정은 사용할 데이터를 이해하고 그 데이터가 해결해야 할 문제와 어떤 관련이 있는지를 이해하는 일이다.

# 첫 번째 애플리케이션: 붓꽃의 품종 분류

1. 한 아마추어 식물학자가 들에서 발견한 붓꽃의 품종을 알고 싶다고 가정해보자

2. 이 식물학자는 붓꽃의 꽃잎과 꽃받침의 폭과 길이를 센티미터 단위로 측정했다.

3. 또 전문 식물학자가 setosa, versicolor, virginica 종으로 분류한 붓꽃의 측정 데이터도 가지고 있다.

4. 이 측정값을 이용해서 앞에서 채집한 붓꽃이 어떤 품종인지 구분하려고 한다.

5. 이 아마추어 식물학자가 야생에서 채집한 붓꽃은 이 세 종류뿐이라고 가정해보자

6. 붓꽃의 품종을 정확하게 분류한 데이터를 가지고 있으므로 이 문제는 지도 학습에 속한다.

7. 이 경우에는 몇 가지 선택사항(붓꽃의 품종) 중 하나를 선택하는 문제다.

8. 그러므로 이 예는 분류(classification) 문제에 해당한다.

9. 출력될 수 있는 값(붓꽃의 종류)들을 클래스(class)라고 한다.

10. 데이터셋에 있는 붓꽃 데이터는 모두 세 클래스 중 하나에 속한다.

11. 따라서 이 예는 세 개의 클래스를 분류하는 문제이다.

12. 데이터 포인트 하나(붓꽃 하나)에 대한 기대 출력은 꽃의 품종이 된다.

13. 이런 특정 데이터 포인트에 대한 출력, 즉 품종을 레이블(label)이라고 한다.

# 데이터 적재

1. 우리가 사용할 데이터셋은 머신러닝과 통계 분야에서 오래전부터 사용해온 붓꽃 데이터셋이다.

2. 이 데이터는 scikit-leran의 datasets 모듈에 포함되어 있다.

3. load_iris 함수를 사용해서 데이터를 적재해보자.

```

from skleran.datasets import load_iris
iris_dataset = load_iris()

```

4. load_iris가 반환한 iris 객체는 파이쎤의 딕셔너리와 유사한 Bunch 클래스의 객체이다. 즉 키와 값으로 구성되어 있다.

```

iris_dataset.keys()

iris_dataset의 키:
dick_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])

```

5. DESCR 키에는 데이터셋에 대한 간략한 설명이 들어 있다.

6. target_names의 값은 우리가 예측하려는 붓꽃 품종의 이름을 문자열 배열로 가지고 있다.

```

iris_dataset['target_names']
['setosa', 'versicolor', 'virginica']

```

7. feature_names의 값은 각 특성을 설명하는 문자열 리스트이다.

```

iris_dataset(['feature_names'])
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']

```

8. 실제 데이터는 target 과 data 필드에 들어 있다.

9. data는 꽃잎의 길이와 폭, 꽃받침의 길이와 폭을 수치 값으로 가지고 있는 Numpy 배열이다.

10. data 배열의 행은 개개의 꽃이 되며 열은 각 꽃에서 구한 네 개의 측정치이다.

11. 이 배열은 150개의 붓꽃 데이터를 가지고 있다.

12. 머신러닝에서 각 아이템은 샘플이라 하고 속성은 특성이라 부른다.

13. 그러므로 data 배열의 크기는 샘플의 수에 특성의 수를 곱한 값이 된다.

14. target 배열은 샘플 붓꽃의 품종을 담은 NumPy 배열이다.

15. target은 각 원소가 붓꽃 하나에 해당하는 1차원 배열이다.

# 성과 측정: 훈련 데이터와 테스트 데이터

1. 이 데이터로 머신러닝 모델을 만들고 새로운 데이터의 품종을 예측하려 한다.

2. 하지만 만든 모델을 새 데이터에 적용하기 전에 이 모델이 진짜 잘 작동하는지 알아야 한다.

3. 즉 우리가 만든 모델의 예측을 신뢰할 수 있는지 알아야 한다.

4. 불행히도 모델을 만들 때 쓴 데이터는 평가 목적으로 사용할 수 없다.

5. 모델이 훈련 데이터를 그냥 전부 기억할 수 있으니 훈련 데이터에 속한 어떤 데이터라도 정확히 맞출 수 있기 때문이다.

6. 이렇게 데이터를 기억한다는 것은 모델을 잘 일반화하지 않았다는 뜻이다.

7. 모델의 성능을 측정하려면 레이블을 알고 있는(이전에 본 적 없는?) 새 데이터를 모델에 적용해봐야 한다.

8. 이를 위해 우리가 가지고 있는 레이블된 데이터(150개의 붓꽃 데이터)를 두 그룹으로 나눈다.

9. 그중 하나는 머신러닝 모델을 만들 때 사용하며, 훈련 데이터 혹은 훈련 세트라고 한다.

10. 나머지는 모델이 얼마나 잘 작동하는지 측정하는 데 사용하며, 이를 테스트 데이터, 테스트 세트 혹은 홀드아웃 세트라고 부른다.

11. scikit-learn은 데이터셋을 섞어서 나눠주는 train_test_split 함수를 제공한다.

12. 이 함수는 전체 행 중 75%를 레이블 데이터와 함께 훈련 세트로 뽑는다.

13. 나머지 25%는 레이블 데이터와 함께 테스트 세트가 된다.

14. 훈련 세트와 테스트 세트를 얼만큼씩 나눌지는 상황에 따라 다르지만 전체의 25%를 테스트 세트로 사용하는 것은 일반적으로 좋은 선택이다.

15. scikit-learn에서 데이터는 대문자 X로 표시하고 레이블은 소문자 y로 표기한다.

16. train_test_split 함수로 데이터를 나누기 전에 유사 난수 생성기를 사용해 데이터셋을 무작위로 섞어야 한다.

```

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)

```

# 가장 먼저 할 일: 데이터 살펴보기

1. 머신러닝 모델을 만들기 전에 머신러닝이 없어도 풀 수 있는 문제는 아닌지, 혹은 필요한 정보가 누락되는지 않았는지 데이터를 조사해보는 것이 좋다.

2. 시각화는 데이터를 조사하는 아주 좋은 방법이다. 산점도(scatter point)가 그중 하나이다.

3. 산점도는 데이터에서 한 특성을 x 축에 놓고 다른 하나는 y 축에 놓아 각 데이터 포인트를 하나의 점으로만 나타내는 그래프이다.

4. 아쉽게도 컴퓨터 화면은 2ㅊ아ㅝㄴ이라 한 번에 2개(혹은 3개)의 특성만 그릴 수 있다.

# 첫 번째 머신러닝 모델: k-최근접 이웃 알고리즘

1. scikit-leran은 다양한 분류 알고리즘을 제공한다.

2. 여기서는 비교적 이해하기 쉬운 k-최근접 이웃 분류기를 사용한다.

3. 이 모델은 단순히 훈련 데이터를 저장하여 만들어진다.

4. k-최근접 이웃 알고리즘에서 k는 가장 가까운 이웃 '하나'가 아니라 훈련 데이터에서 새로운 데이터 포인트에 가장 가까운 'k개'의 이웃을 찾는다는 뜻이다.

5. 그런 다음 이 이웃들의 클래스 중 빈도가 가장 높은 클래스를 예측값으로 사용한다.

6. k-최근접 이웃 분류 알고리즘은 neighbors 모듈 아래 KNeighborsClassifer 클래스에 구현되어 있다.

7. 모델을 사용하려면 클래스로부터 객체를 만들어야 한다.

8. 이때 모델에 필요한 매개변수를 넣는다.

9. KNeighborsClassifier에서 가장 중요한 매개변수는 이웃의 개수다.

10. 우리는 1로 지정한다.

```

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)

```

# 예측하기

1. 이제 이 모델을 사용해서 정확한 레이블을 모르는 새 데이터에 대해 예측을 만들 수 있다.

2. 야생에서 꽃받침의 길이가 5cm, 폭이 2.9cm이고 꽃잎의 길이가 1cm, 폭이 0.2cm인 붓꽃을 보았다고 가정해보자

3. 그럼 이 붓꽃의 품종은 무엇일까?

4. 먼저 이 측정값을 Numpy 배열, 즉 샘플의 수(1)에 특성의 수(4)를 곱한 크기의 NumPy 배열로 만들어보자